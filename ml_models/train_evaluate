import numpy as np
import pandas as pd
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split, GridSearchCV
import xgboost as xgb

def split_data(X, y, test_size=0.2):
    """
    Splits the dataset into training and test sets.
    """
    return train_test_split(X, y, test_size=test_size, random_state=42)

def train_model(X_train, y_train, model, params_grid):
    """
    Trains a model using GridSearchCV to find the best hyperparameters.
    """
    grid_search = GridSearchCV(model, params_grid, cv=5, scoring='neg_mean_squared_error')
    grid_search.fit(X_train, y_train)
    return grid_search.best_estimator_, grid_search.best_params_

def evaluate_model(model, X_train, y_train, X_test, y_test):
    """
    Evaluates the model's performance on both training and test sets.
    """
    predictions_train = model.predict(X_train)
    predictions_test = model.predict(X_test)
    rmse_train = np.sqrt(mean_squared_error(y_train, predictions_train))
    rmse_test = np.sqrt(mean_squared_error(y_test, predictions_test))
    r2_train = r2_score(y_train, predictions_train)
    r2_test = r2_score(y_test, predictions_test)
    return {
        'params': model.get_params(),
        'R2_Train': r2_train,
        'RMSE_Train': rmse_train,
        'R2_Test': r2_test,
        'RMSE_Test': rmse_test
    }

def train_evaluate(X, y):
    """
    Main function to execute the model training and evaluation pipeline for different models.
    """
    models_params = {
        'Lasso': (Lasso(), {'alpha': [0.001, 0.01, 0.1, 1, 10]}),
        'Decision Tree': (DecisionTreeRegressor(), {'max_depth': [None, 10, 20, 30], 'min_samples_leaf': [1, 2, 4], 'min_samples_split': [2, 10, 20]}),
        'Random Forest': (RandomForestRegressor(), {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_leaf': [1, 2, 4]}),
        'XGBoost': (xgb.XGBRegressor(), {'n_estimators': [50, 100, 200], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.2]})
    }
    
    results = {}
    X_train, X_test, y_train, y_test = split_data(X, y)
    
    for model_name, (model, params) in models_params.items():
        best_model, best_params = train_model(X_train, y_train, model, params)
        model_results = evaluate_model(best_model, X_train, y_train, X_test, y_test)
        model_results['best_params'] = best_params
        results[model_name] = model_results
    
    return results

