import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from scipy.spatial.distance import cosine

def generate_baseData():
  cov_matrix = np.array([[1, 0], [0, 1]])
  data_set = np.random.multivariate_normal(mean=[0, 0], cov=cov_matrix, size=1000)
  df_set = pd.DataFrame(data_set, columns=['N1', 'N2'])
  return df_set


def generate_data(df_set, correlation, coefficients=None):
    df_set = generate_baseData()
    X1 = df_set['N1']
    X2 = (correlation)*df_set['N1'] + (1-correlation)*df_set['N2']

    synthetic_df = pd.DataFrame({'X1': X1, 'X2': X2})

    # Check if coefficients are provided, if not, generate them randomly
    if coefficients is None:
        np.random.seed(42)  # For reproducible results
        coefficients = np.random.rand(2)  # Generating two random coefficients

    # Ensure that the coefficients is an array-like with two elements
    assert len(coefficients) == 2, "Coefficients should be an array-like with two elements."

    # Using the coefficients in the linear combination to compute 'Y'
    synthetic_df['Y'] = coefficients[0] * synthetic_df['X1'] + coefficients[1] * synthetic_df['X2']
    
    return synthetic_df, coefficients

# Function to compute feature contributions
def compute_feature_contributions(model, X_test):
    if hasattr(model, 'feature_importances_'):
        return model.feature_importances_
    elif hasattr(model, 'coef_'):
        return np.abs(model.coef_)
    elif hasattr(model, 'perm_importance'):
        return model.perm_importance.importances_mean
    else:
        return None

# Function to calculate cosine similarity using scipy
def calculate_cosine_similarity(vector1, vector2):
    return 1 - cosine(vector1, vector2)

# Function to calculate SHAP values
def calculate_shap_values(model, X_test):
    explainer = shap.Explainer(model, X_test)
    shap_values = explainer.shap_values(X_test)
    return shap_values

# def predict_function(model,X):
#   return model.predict(X)

# def calculate_maple_values(model, X_test):
#   explainer = shap.explainers.other.Maple(predict_function(model,X_train), X_train)
#   # Compute MAPLE SHAP values
#   maple_values = explainer.attributions(X_test)
#   return maple_values


def calculate_maple_values(model, X_train, X_test):
    # Define the predict function for MAPLE explainer
    def predict_function(X):
        return model.predict(X)
    
    # Create MAPLE explainer
    explainer = shap.explainers.other.Maple(predict_function, X_train)
    
    # Compute MAPLE SHAP values
    maple_values = explainer.attributions(X_test)
    
    # Return the mean of MAPLE SHAP values
    return maple_values.mean(axis=0)

def run_experiment(repetitions, correlation_values, coefficients=None):
  # Results dictionary to store all data
  results = {
             'Correlation': [], 'Experiment': [], 'Model': [], 
             'Cosine Similarity (Synthetic vs. Model)': [],
            'Cosine Similarity (Model vs. SHAP)': [], 
             'Cosine Similarity (Synthetic vs. SHAP)': [],
             'Cosine Similarity (Synthetic vs. MAPLE)':[]}

  # Iterate over correlation values and repetitions
  for _ in range(repetitions):
    
    df_set = generate_baseData() # 2d multivariate
    
    # Check if coefficients are provided, if not, generate them randomly
    # if coefficients is None:
    coefficients = np.random.rand(2)  # Generating two random coefficients

    for correlation in correlation_values:
      # Linearly combine to attain particular correlation 
      df, coefficients = generate_data(df_set, correlation, coefficients)

      # Split data into features (X) and target (Y)
      X = df[['X1', 'X2']]
      y = df['Y']

      # Split data into training and testing sets
      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

      # Train white-box models
      models = {
          'Linear Regression': LinearRegression(),
          'Decision Tree': DecisionTreeRegressor(),
          'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)
      }

      for model_name, model in models.items():
          # print(model_name)
          model.fit(X_train, y_train)
          y_pred = model.predict(X_test)
          mse = mean_squared_error(y_test, y_pred)

          # Compute feature contributions
          ground_truth_contributions = coefficients
          learned_model_contributions = compute_feature_contributions(model, X_test)
          shap_values = calculate_shap_values(model, X_test).mean(axis=0)
          maple_values = calculate_maple_values(model,X_train, X_test)


          if learned_model_contributions is not None:
              # Normalize feature contributions to unit vectors
              ground_truth_contributions_normalized = np.abs(ground_truth_contributions)
              learned_model_contributions_normalized = np.abs(learned_model_contributions)
              shap_values_normalized = np.abs(shap_values)
              maple_values_normalized = np.abs(maple_values)

              # Calculate cosine similarity
              similarity_synthetic_model = calculate_cosine_similarity(ground_truth_contributions_normalized, learned_model_contributions_normalized)
              similarity_model_shap = calculate_cosine_similarity(learned_model_contributions_normalized, shap_values_normalized)
              similarity_synthetic_shap = calculate_cosine_similarity(ground_truth_contributions_normalized, shap_values_normalized)

              similarity_synthetic_maple = calculate_cosine_similarity(ground_truth_contributions_normalized, maple_values_normalized)

              # Store results
              # results['Coefficients'].append(coefficients)
              results['Correlation'].append(correlation)
              results['Experiment'].append(_ + 1)
              results['Model'].append(model_name)
              results['Cosine Similarity (Synthetic vs. Model)'].append(similarity_synthetic_model)
              results['Cosine Similarity (Model vs. SHAP)'].append(similarity_model_shap)
              results['Cosine Similarity (Synthetic vs. SHAP)'].append(similarity_synthetic_shap)
              results['Cosine Similarity (Synthetic vs. MAPLE)'].append(similarity_synthetic_maple)

  # Convert results to a DataFrame
  results_df = pd.DataFrame(results)
  return results_df
